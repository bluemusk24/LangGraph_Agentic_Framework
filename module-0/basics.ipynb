{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "494f7269-cb42-487b-8d76-aef330aeb421",
   "metadata": {},
   "source": [
    "#### Testing Ollama with Langchain locally on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78fc7bb9-08c4-4165-81ff-5aa89e5c65dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The title of ‚Äúbest‚Äù can vary depending on whether you‚Äôre looking at current form, overall influence, or historical impact. Here‚Äôs a quick snapshot of the top names right now:\\n\\n| Player | Club | Position | 2023‚Äë24 Highlights |\\n|--------|------|----------|--------------------|\\n| **Lionel Messi** | Inter Miami (MLS) | Forward | 17 goals, 8 assists in 25 MLS games; record‚Äëbreaking 23‚Äëpoint season in the Concacaf Champions League. |\\n| **Erling Haaland** | Manchester City (Premier League) | Forward | 34 league goals (a season‚Äëlong record) and 30 goals in 36 Champions League matches; key to City‚Äôs deep run. |\\n| **Kylian Mbapp√©** | PSG (Ligue 1) | Forward | 26 league goals, 8 assists; vital to France‚Äôs Euro 2024 semi‚Äëfinal push. |\\n| **Karim Benzema** | Al‚ÄëIttihad (Saudi Pro League) | Forward | 20 league goals; the highest‚Äëscoring African player globally. |\\n\\n**Why Messi still gets most ‚Äúall‚Äëtime‚Äù votes**  \\n- 7 Ballon d‚ÄôOrs (world‚Äôs best individual award).  \\n- Record for most career goals in both club and international competitions.  \\n- Longevity and consistency across multiple leagues.\\n\\n**Why Haaland is the current ‚Äúplayer of the year‚Äù conversation**  \\n- Raw goal‚Äëscoring rate surpasses every other striker globally.  \\n- Integral to Manchester City‚Äôs league and Champions League success.  \\n\\n**Broader view**  \\n- **Mbapp√©**: Explosive pace, goal‚Äëscoring, and all‚Äëround play make him the most valuable ‚Äúfuture‚Äëproof‚Äù player.  \\n- **Benzema**: A master strategist and consistent threat, proving that top scorers can also be playmakers.\\n\\n**Bottom line**  \\nIf you‚Äôre judging by trophy haul and lifetime achievements, Messi tops the list. For pure current‚Äëseason impact, Haaland is unmatched. Mbapp√© bridges the two, promising a long, influential career.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "model = OllamaLLM(model=\"gpt-oss:20b-cloud\")\n",
    "\n",
    "model.invoke('tell me the best soccer player in the world')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70c1553-88af-4d87-b3ca-ba1b17ba4067",
   "metadata": {},
   "source": [
    "* the above format is used to call Ollama model with Langchain, but I'll go with the video lecture of using ChatOllama format below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c86618f4-2661-4d05-8165-dbb687dc5bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "ollama_chat = ChatOllama(model=\"gpt-oss:20b-cloud\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3f333e9-8fe9-41b9-93f0-29b04625a94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! üëã How can I help you today?', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b-cloud', 'created_at': '2025-10-06T17:00:50.603045316Z', 'done': True, 'done_reason': 'stop', 'total_duration': 481595232, 'load_duration': None, 'prompt_eval_count': 76, 'prompt_eval_duration': None, 'eval_count': 52, 'eval_duration': None, 'model_name': 'gpt-oss:20b-cloud'}, id='run--cdf4a90b-818e-4080-ba8b-77f938f768ed-0', usage_metadata={'input_tokens': 76, 'output_tokens': 52, 'total_tokens': 128})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Create a message\n",
    "msg = HumanMessage(content=\"Hello world\", name=\"Emmanuel\")\n",
    "\n",
    "# Message list\n",
    "messages = [msg]\n",
    "\n",
    "# Invoke the model with a list of messages \n",
    "ollama_chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be6122e6-6c95-400a-8281-586f19eba772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! üëã How can I help you today?', additional_kwargs={}, response_metadata={'model': 'gpt-oss:20b-cloud', 'created_at': '2025-10-06T17:01:23.061916801Z', 'done': True, 'done_reason': 'stop', 'total_duration': 830302519, 'load_duration': None, 'prompt_eval_count': 76, 'prompt_eval_duration': None, 'eval_count': 98, 'eval_duration': None, 'model_name': 'gpt-oss:20b-cloud'}, id='run--64f1b78f-9bd4-412b-a89c-776b8fb60a9e-0', usage_metadata={'input_tokens': 76, 'output_tokens': 98, 'total_tokens': 174})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke model with a string message\n",
    "ollama_chat.invoke(\"hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f8121b-57c8-48fb-baa5-1bc426d24483",
   "metadata": {},
   "source": [
    "### Search Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30fec6ee-dcdd-42d1-95ee-663814076c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "tavily_key = os.getenv('TAVILY_API_KEY')\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2448e21c-c59c-41f7-8633-7600e8cd9769",
   "metadata": {},
   "source": [
    "#### search using Tavily as web search tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "217d9092-15ac-430a-a072-d70450de6a5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12720/3227139208.py:2: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  tavily_search = TavilySearchResults(max_results=3)\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tavily_search = TavilySearchResults(max_results=3)\n",
    "search_docs = tavily_search.invoke(\"What is LangGraph?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9345d95-683d-4ce4-ae54-27f3c5c2277e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'What is LangGraph? - IBM',\n",
       "  'url': 'https://www.ibm.com/think/topics/langgraph',\n",
       "  'content': 'LangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. It provides a set of tools and libraries that enable users to create, run and optimize large language models (LLMs) in a scalable and efficient manner. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. [...] Agent systems: LangGraph provides a framework for building agent-based systems, which can be used in applications such as robotics, autonomous vehicles or video games.\\n\\nLLM applications: By using LangGraph‚Äôs capabilities, developers can build more sophisticated AI models that learn and improve over time. Norwegian Cruise Line uses LangGraph to compile, construct and refine guest-facing AI solutions. This capability allows for improved and personalized guest experiences. [...] By using a graph-based architecture, LangGraph enables users to scale artificial intelligence workflows without slowing down or sacrificing efficiency. LangGraph uses enhanced decision-making by modeling complex relationships between nodes, which means it uses AI agents to analyze their past actions and feedback. In the world of LLMs, this process is referred to as reflection.',\n",
       "  'score': 0.94608605},\n",
       " {'title': 'What is LangGraph? - GeeksforGeeks',\n",
       "  'url': 'https://www.geeksforgeeks.org/machine-learning/what-is-langgraph/',\n",
       "  'content': '# What is LangGraph?\\n\\nLast Updated : \\n25 Aug, 2025\\n\\nSuggest changes\\n\\n1 Like\\n\\nLangGraph is an open-source framework built by LangChain that streamlines the creation and management of AI agent workflows. At its core, LangGraph combines large language models (LLMs) with graph-based architectures allowing developers to map, organize and optimize how AI agents interact and make decisions.',\n",
       "  'score': 0.9412289},\n",
       " {'title': 'LangGraph Tutorial: What Is LangGraph and How to Use It?',\n",
       "  'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
       "  'content': \"# LangGraph Tutorial: What Is LangGraph and How to Use It?\\n\\nLangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner.\\n\\nJun 26, 2024  ¬∑ 12 min read [...] Imagine you're building a complex, multi-agent large language model (LLM) application. It's exciting, but it comes with challenges: managing the state of various agents, coordinating their interactions, and handling errors effectively. This is where LangGraph can help.\\n\\nLangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner. [...] For applications requiring autonomous decision-making, LangGraph enables the creation of agents that can perform tasks independently based on user inputs and predefined logic.\\n\\nThese agents can execute complex workflows, interact with other systems, and adapt to new information dynamically. LangGraph's structured framework ensures that each agent operates efficiently and effectively, making it suitable for tasks like automated customer support, data processing, and system monitoring.\",\n",
       "  'score': 0.93694025}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206ca76e-4afb-4f80-b981-f7366a57d5a6",
   "metadata": {},
   "source": [
    "#### search using wikipedia as web search tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9eb73df-2105-48fb-87c2-a2d7fe7436b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import WikipediaRetriever\n",
    "\n",
    "retriever = WikipediaRetriever()\n",
    "\n",
    "wiki_docs = retriever.invoke(\"LangGraph?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ac908412-1d7d-415c-9986-aa0bfef58c42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n",
      "\n",
      "\n",
      "== History ==\n",
      "LangChain was launched in October 2022 as an open source project by Harrison Chase, while working at machine learning startup Robust Intelligence. In April 2023, LangChain had incorporated and the new startup raised over $20 million in funding at a valuation of at least $200 million from venture firm Sequoia Capital, a week after announcing a $10 million seed investment from Benchmark.\n",
      "In the third quarter of 2023, the LangChain Expression Language (LCEL) was introduced, which provides a declarative way to define chains of actions.\n",
      "In October 2023 LangChain introduced LangServe, a deployment tool to host LCEL code as a production-ready API.\n",
      "In February 2024 LangChain released LangSmith, a closed-source observability and evaluation platform for LLM applications, and announced a US $25 million Series A led by Sequoia Capital. On 14 May 2025 the company launched LangGraph Platform into general availability, providing managed infrastructure for deploying long-running, stateful AI agents.\n",
      "\n",
      "\n",
      "== Capabilities ==\n",
      "LangChain's developers highlight the framework's applicability to use-cases including chatbots, retrieval-augmented generation,  document summarization, and synthetic data generation.\n",
      "As of March 2023, LangChain included integrations with systems including Amazon, Google, and Microsoft Azure cloud storage; API wrappers for news, movie information, and weather; Bash for summarization, syntax and semantics checking, and execution of shell scripts; multiple web scraping subsystems and templates; few-shot learning prompt generation support; finding and summarizing \"todo\" tasks in code; Google Drive documents, spreadsheets, and presentations summarization, extraction, and creation; Google Search and Microsoft Bing web search; OpenAI, Anthropic, and Hugging Face language models; iFixit repair guides and wikis search and summarization; MapReduce for question answering, combining documents, and question generation; N-gram overlap scoring; PyPDF, pdfminer, fitz, and pymupdf for PDF file text extraction and manipulation; Python and JavaScript code generation, analysis, and debugging; Milvus vector database to store and retrieve vector embeddings; Weaviate vector database to cache embedding and data objects; Redis cache database storage; Python RequestsWrapper and other methods for API requests; SQL and NoSQL databases including JSON support; Streamlit, including for logging; text mapping for k-nearest neighbors search; time zone conversion and calendar operations; tracing and recording stack symbols in threaded and asynchronous subprocess runs; and the Wolfram Alpha website and SDK. As of April 2023, it can read from more than 50 document types and data sources.\n",
      "\n",
      "\n",
      "== LangChain tools ==\n",
      "\n",
      "\n",
      "== References ==\n",
      "\n",
      "\n",
      "== External links ==\n",
      "\n",
      "Official website\n",
      "Discord server support hub\n",
      "Langchain-ai on GitHub\n"
     ]
    }
   ],
   "source": [
    "print(wiki_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128d9915-50c0-4a31-ad70-fe90e5db829d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
