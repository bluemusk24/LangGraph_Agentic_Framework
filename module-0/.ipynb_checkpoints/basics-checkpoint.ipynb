{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "494f7269-cb42-487b-8d76-aef330aeb421",
   "metadata": {},
   "source": [
    "#### Testing Ollama with Langchain locally on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78fc7bb9-08c4-4165-81ff-5aa89e5c65dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Determining the \"best soccer player in the world\" is subjective and can vary based on personal preferences, team dynamics, regional influences, historical significance, and more. There are several well-regarded athletes who have made significant contributions to their teams and regions.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "model = OllamaLLM(model=\"falcon3:1b-instruct-q4_K_M\")\n",
    "\n",
    "model.invoke('tell me the best soccer player in the world')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70c1553-88af-4d87-b3ca-ba1b17ba4067",
   "metadata": {},
   "source": [
    "* the above format is used to call Ollama model with Langchain, but I'll go with the video lecture of using ChatOllama format below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c86618f4-2661-4d05-8165-dbb687dc5bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "ollama_chat = ChatOllama(model=\"falcon3:1b-instruct-q4_K_M\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3f333e9-8fe9-41b9-93f0-29b04625a94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today? If you have any questions or need information on a particular topic, feel free to ask.', additional_kwargs={}, response_metadata={'model': 'falcon3:1b-instruct-q4_K_M', 'created_at': '2025-09-11T17:41:15.201970567Z', 'done': True, 'done_reason': 'stop', 'total_duration': 2110403919, 'load_duration': 288472611, 'prompt_eval_count': 13, 'prompt_eval_duration': 254387206, 'eval_count': 28, 'eval_duration': 1564398463, 'model_name': 'falcon3:1b-instruct-q4_K_M'}, id='run--34a23803-d958-4a7d-8a07-7fd37108f144-0', usage_metadata={'input_tokens': 13, 'output_tokens': 28, 'total_tokens': 41})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Create a message\n",
    "msg = HumanMessage(content=\"Hello world\", name=\"Emmanuel\")\n",
    "\n",
    "# Message list\n",
    "messages = [msg]\n",
    "\n",
    "# Invoke the model with a list of messages \n",
    "ollama_chat.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be6122e6-6c95-400a-8281-586f19eba772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={}, response_metadata={'model': 'falcon3:1b-instruct-q4_K_M', 'created_at': '2025-09-11T17:41:38.537898391Z', 'done': True, 'done_reason': 'stop', 'total_duration': 1021921972, 'load_duration': 322013520, 'prompt_eval_count': 13, 'prompt_eval_duration': 183934224, 'eval_count': 10, 'eval_duration': 509358500, 'model_name': 'falcon3:1b-instruct-q4_K_M'}, id='run--5ff0e9eb-8840-4882-a100-8b9175de649c-0', usage_metadata={'input_tokens': 13, 'output_tokens': 10, 'total_tokens': 23})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke model with a string message\n",
    "ollama_chat.invoke(\"hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f8121b-57c8-48fb-baa5-1bc426d24483",
   "metadata": {},
   "source": [
    "### Search Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "30fec6ee-dcdd-42d1-95ee-663814076c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "tavily_key = os.getenv('TAVILY_API_KEY')\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "217d9092-15ac-430a-a072-d70450de6a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tavily_search = TavilySearchResults(max_results=3)\n",
    "search_docs = tavily_search.invoke(\"What is LangGraph?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9345d95-683d-4ce4-ae54-27f3c5c2277e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'What is LangGraph?',\n",
       "  'url': 'https://www.analyticsvidhya.com/blog/2024/07/langgraph-revolutionizing-ai-agent/',\n",
       "  'content': 'To sum up, LangGraph is a major advancement in the development of AI agents. It enables developers to push the limits of what’s possible with AI agents by eliminating the shortcomings of earlier systems and offering a flexible, graph-based framework for agent construction and execution. LangGraph is positioned to influence the direction of artificial intelligence significantly in the future. [...] LangGraph is a library built on top of Langchain that is designed to facilitate the creation of cyclic graphs for large language model (LLM) – based AI agents.\\n It views agent Objective Points about LangGraph and workflows as cyclic graph topologies, allowing for more variable and nuanced agent behaviors than linear execution models. [...] Frameworks such as LangGraph are becoming increasingly important as AI develops. LangGraph is making the next generation of AI applications possible by offering a versatile and strong framework for developing and overseeing AI agents.',\n",
       "  'score': 0.95143646},\n",
       " {'title': 'What is LangGraph?',\n",
       "  'url': 'https://www.ibm.com/think/topics/langgraph',\n",
       "  'content': 'LangGraph, created by LangChain, is an open source AI agent framework designed to build, deploy and manage complex generative AI agent workflows. It provides a set of tools and libraries that enable users to create, run and optimize large language models (LLMs) in a scalable and efficient manner. At its core, LangGraph uses the power of graph-based architectures to model and manage the intricate relationships between various components of an AI agent workflow. [...] Agent systems: LangGraph provides a framework for building agent-based systems, which can be used in applications such as robotics, autonomous vehicles or video games.\\n\\nLLM applications: By using LangGraph’s capabilities, developers can build more sophisticated AI models that learn and improve over time. Norwegian Cruise Line uses LangGraph to compile, construct and refine guest-facing AI solutions. This capability allows for improved and personalized guest experiences. [...] By using a graph-based architecture, LangGraph enables users to scale artificial intelligence workflows without slowing down or sacrificing efficiency. LangGraph uses enhanced decision-making by modeling complex relationships between nodes, which means it uses AI agents to analyze their past actions and feedback. In the world of LLMs, this process is referred to as reflection.',\n",
       "  'score': 0.95067275},\n",
       " {'title': 'Overview - Docs by LangChain',\n",
       "  'url': 'https://docs.langchain.com/oss/python/langgraph/overview',\n",
       "  'content': 'Trusted by companies shaping the future of agents - including Klarna, Replit, Elastic, and more - LangGraph is a low-level orchestration framework for building, managing, and deploying long-running, stateful agents.',\n",
       "  'score': 0.9471519}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206ca76e-4afb-4f80-b981-f7366a57d5a6",
   "metadata": {},
   "source": [
    "* from langchain_community.tools import wikipedia\n",
    "\n",
    "* wiki_search = wikipedia(max_results=2)\n",
    "\n",
    "#### research using wikipedia as web search tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38f112e-8a4a-4f9b-82b2-c394e5fe2adb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
