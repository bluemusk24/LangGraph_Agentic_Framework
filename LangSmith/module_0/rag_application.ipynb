{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Simple RAG](../../images/simple_rag.png)\n",
    "\n",
    "In this notebook, we're going to set up a simple RAG application that we'll be using as we learn more about LangSmith.\n",
    "\n",
    "RAG (Retrieval Augmented Generation) is a popular technique for providing LLMs with relevant documents that will enable them to better answer questions from users. \n",
    "\n",
    "In our case, we are going to index some LangSmith documentation!\n",
    "\n",
    "LangSmith makes it easy to trace any LLM application, no LangChain required!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you set your environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "langsmith_key = os.getenv('LANGSMITH_API_KEY')\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langsmith-academy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple RAG application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object, got 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     10\u001b[39m RAG_SYSTEM_PROMPT = \u001b[33m\"\"\"\u001b[39m\u001b[33mYou are an assistant for question-answering tasks. \u001b[39m\n\u001b[32m     11\u001b[39m \u001b[33mUse the following pieces of retrieved context to answer the latest question in the conversation. \u001b[39m\n\u001b[32m     12\u001b[39m \u001b[33mIf you don\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt know the answer, just say that you don\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt know. \u001b[39m\n\u001b[32m     13\u001b[39m \u001b[33mUse three sentences maximum and keep the answer concise.\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     16\u001b[39m nest_asyncio.apply()\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m retriever = \u001b[43mget_vector_db_retriever\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[33;03mretrieve_documents\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[33;03m- Returns documents fetched from a vectorstore based on the user's question\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;129m@traceable\u001b[39m(run_type=\u001b[33m\"\u001b[39m\u001b[33mchain\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mretrieve_documents\u001b[39m(question: \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/emman/LangGraph_lectures/LangSmith/module_0/utils.py:10\u001b[39m, in \u001b[36mget_vector_db_retriever\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_vector_db_retriever\u001b[39m():\n\u001b[32m      9\u001b[39m     persist_path = os.path.join(tempfile.gettempdir(), \u001b[33m\"\u001b[39m\u001b[33munion.parquet\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     embed_model = \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mall-MiniLM-L6-v2\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# If vector store exists, then load it\u001b[39;00m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(persist_path):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/emman/LangGraph_lectures/.venv/lib/python3.11/site-packages/langchain_huggingface/embeddings/huggingface.py:69\u001b[39m, in \u001b[36mHuggingFaceEmbeddings.__init__\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m     67\u001b[39m \u001b[38;5;28msuper\u001b[39m().\u001b[34m__init__\u001b[39m(**kwargs)\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[import]\u001b[39;00m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     71\u001b[39m     msg = (\n\u001b[32m     72\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import sentence_transformers python package. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     73\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/emman/LangGraph_lectures/.venv/lib/python3.11/site-packages/sentence_transformers/__init__.py:10\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mwarnings\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     11\u001b[39m     export_dynamic_quantized_onnx_model,\n\u001b[32m     12\u001b[39m     export_optimized_onnx_model,\n\u001b[32m     13\u001b[39m     export_static_quantized_openvino_model,\n\u001b[32m     14\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcross_encoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     CrossEncoder,\n\u001b[32m     17\u001b[39m     CrossEncoderModelCardData,\n\u001b[32m     18\u001b[39m     CrossEncoderTrainer,\n\u001b[32m     19\u001b[39m     CrossEncoderTrainingArguments,\n\u001b[32m     20\u001b[39m )\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/emman/LangGraph_lectures/.venv/lib/python3.11/site-packages/sentence_transformers/backend/__init__.py:3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mload\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_onnx_model, load_openvino_model\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptimize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m export_optimized_onnx_model\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mquantize\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m export_dynamic_quantized_onnx_model, export_static_quantized_openvino_model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/emman/LangGraph_lectures/.venv/lib/python3.11/site-packages/sentence_transformers/backend/load.py:7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlogging\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpathlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfiguration_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PretrainedConfig\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msentence_transformers\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackend\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _save_pretrained_wrapper, backend_should_export, backend_warn_to_save\n\u001b[32m     11\u001b[39m logger = logging.getLogger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/emman/LangGraph_lectures/.venv/lib/python3.11/site-packages/transformers/__init__.py:27\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m dependency_versions_check\n\u001b[32m     28\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     29\u001b[39m     OptionalDependencyNotAvailable,\n\u001b[32m     30\u001b[39m     _LazyModule,\n\u001b[32m   (...)\u001b[39m\u001b[32m     36\u001b[39m     is_pretty_midi_available,\n\u001b[32m     37\u001b[39m )\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Note: the following symbols are deliberately exported with `as`\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# so that mypy, pylint or other static linters can recognize them,\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# given that they are not exported using `__all__` in this file.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/emman/LangGraph_lectures/.venv/lib/python3.11/site-packages/transformers/dependency_versions_check.py:16\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdependency_versions_table\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m deps\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mversions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m require_version, require_version_core\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# order specific notes:\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;66;03m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[32m     25\u001b[39m pkgs_to_check_at_runtime = [\n\u001b[32m     26\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtqdm\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     37\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpyyaml\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     38\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/emman/LangGraph_lectures/.venv/lib/python3.11/site-packages/transformers/utils/__init__.py:24\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpackaging\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m version\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mauto_docstring\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     ClassAttrs,\n\u001b[32m     26\u001b[39m     ClassDocstring,\n\u001b[32m     27\u001b[39m     ImageProcessorArgs,\n\u001b[32m     28\u001b[39m     ModelArgs,\n\u001b[32m     29\u001b[39m     ModelOutputArgs,\n\u001b[32m     30\u001b[39m     auto_class_docstring,\n\u001b[32m     31\u001b[39m     auto_docstring,\n\u001b[32m     32\u001b[39m     get_args_doc_from_source,\n\u001b[32m     33\u001b[39m     parse_docstring,\n\u001b[32m     34\u001b[39m     set_min_indent,\n\u001b[32m     35\u001b[39m )\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbackbone_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BackboneConfigMixin, BackboneMixin\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_template_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DocstringParsingException, TypeHintParsingException, get_json_schema\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/emman/LangGraph_lectures/.venv/lib/python3.11/site-packages/transformers/utils/auto_docstring.py:30\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mregex\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mre\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdoc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     25\u001b[39m     MODELS_TO_PIPELINE,\n\u001b[32m     26\u001b[39m     PIPELINE_TASKS_TO_SAMPLE_DOCSTRINGS,\n\u001b[32m     27\u001b[39m     PT_SAMPLE_DOCSTRINGS,\n\u001b[32m     28\u001b[39m     _prepare_output_docstrings,\n\u001b[32m     29\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgeneric\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ModelOutput\n\u001b[32m     33\u001b[39m PATH_TO_TRANSFORMERS = Path(\u001b[33m\"\u001b[39m\u001b[33msrc\u001b[39m\u001b[33m\"\u001b[39m).resolve() / \u001b[33m\"\u001b[39m\u001b[33mtransformers\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     36\u001b[39m AUTODOC_FILES = [\n\u001b[32m     37\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mconfiguration_*.py\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     38\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmodeling_*.py\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     43\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mfeature_extractor_*.py\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     44\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/emman/LangGraph_lectures/.venv/lib/python3.11/site-packages/transformers/utils/generic.py:34\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mimport_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     35\u001b[39m     is_flax_available,\n\u001b[32m     36\u001b[39m     is_mlx_available,\n\u001b[32m     37\u001b[39m     is_tf_available,\n\u001b[32m     38\u001b[39m     is_torch_available,\n\u001b[32m     39\u001b[39m     is_torch_fx_proxy,\n\u001b[32m     40\u001b[39m     requires,\n\u001b[32m     41\u001b[39m )\n\u001b[32m     44\u001b[39m _CAN_RECORD_REGISTRY = {}\n\u001b[32m     47\u001b[39m logger = logging.get_logger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/emman/LangGraph_lectures/.venv/lib/python3.11/site-packages/transformers/utils/import_utils.py:251\u001b[39m\n\u001b[32m    249\u001b[39m _torch_available, _torch_version = _is_package_available(\u001b[33m\"\u001b[39m\u001b[33mtorch\u001b[39m\u001b[33m\"\u001b[39m, return_version=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _torch_available:\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     _torch_available = \u001b[43mversion\u001b[49m\u001b[43m.\u001b[49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_torch_version\u001b[49m\u001b[43m)\u001b[49m >= version.parse(\u001b[33m\"\u001b[39m\u001b[33m2.1.0\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    252\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _torch_available:\n\u001b[32m    253\u001b[39m         logger.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDisabling PyTorch because PyTorch >= 2.1 is required but found \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_torch_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/emman/LangGraph_lectures/.venv/lib/python3.11/site-packages/packaging/version.py:56\u001b[39m, in \u001b[36mparse\u001b[39m\u001b[34m(version)\u001b[39m\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(version: \u001b[38;5;28mstr\u001b[39m) -> Version:\n\u001b[32m     48\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Parse the given version string.\u001b[39;00m\n\u001b[32m     49\u001b[39m \n\u001b[32m     50\u001b[39m \u001b[33;03m    >>> parse('1.0.dev1')\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m \u001b[33;03m    :raises InvalidVersion: When the version string is not a valid version.\u001b[39;00m\n\u001b[32m     55\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVersion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/c/Users/emman/LangGraph_lectures/.venv/lib/python3.11/site-packages/packaging/version.py:200\u001b[39m, in \u001b[36mVersion.__init__\u001b[39m\u001b[34m(self, version)\u001b[39m\n\u001b[32m    189\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Initialize a Version object.\u001b[39;00m\n\u001b[32m    190\u001b[39m \n\u001b[32m    191\u001b[39m \u001b[33;03m:param version:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    196\u001b[39m \u001b[33;03m    exception will be raised.\u001b[39;00m\n\u001b[32m    197\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# Validate the version and parse it into pieces\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m match = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_regex\u001b[49m\u001b[43m.\u001b[49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m match:\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidVersion(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mversion\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: expected string or bytes-like object, got 'NoneType'"
     ]
    }
   ],
   "source": [
    "from langsmith import traceable\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "import ollama\n",
    "from utils import get_vector_db_retriever\n",
    "\n",
    "MODEL_PROVIDER = \"ollama\"\n",
    "MODEL_NAME = \"gpt-oss:20b-cloud\"\n",
    "#APP_VERSION = \"1.0\"\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\"\"\"\n",
    "\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "\"\"\"\n",
    "retrieve_documents\n",
    "- Returns documents fetched from a vectorstore based on the user's question\n",
    "\"\"\"\n",
    "@traceable(run_type=\"chain\")\n",
    "def retrieve_documents(question: str):\n",
    "    return retriever.invoke(question)\n",
    "\n",
    "\"\"\"\n",
    "generate_response\n",
    "- Calls `call_ollama` to generate a model response after formatting inputs\n",
    "\"\"\"\n",
    "@traceable(run_type=\"chain\")\n",
    "def generate_response(question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": RAG_SYSTEM_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    return call_ollama(messages)\n",
    "\n",
    "\"\"\"\n",
    "call_ollama\n",
    "- Returns the chat completion output from Ollama\n",
    "\"\"\"\n",
    "\n",
    "@traceable(run_type=\"llm\")\n",
    "def call_ollama(\n",
    "    messages: List[dict], model: str = \"gpt-oss:20b-cloud\", temperature: float = 0.0\n",
    "):\n",
    "    response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        stream=False\n",
    "    )\n",
    "    return response\n",
    "\"\"\"\n",
    "langsmith_rag\n",
    "- Calls `retrieve_documents` to fetch documents\n",
    "- Calls `generate_response` to generate a response based on the fetched documents\n",
    "- Returns the model response\n",
    "\"\"\"\n",
    "@traceable(run_type=\"chain\")\n",
    "def langsmith_rag(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response['message']['content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should take a little less than a minute. We are indexing and storing LangSmith documentation in a SKLearn vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'langsmith_rag' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m question = \u001b[33m\"\u001b[39m\u001b[33mWhat is LangSmith used for?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m ai_answer = \u001b[43mlangsmith_rag\u001b[49m(question, langsmith_extra={\u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mwebsite\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mwww.google.com\u001b[39m\u001b[33m\"\u001b[39m}})\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(ai_answer)\n",
      "\u001b[31mNameError\u001b[39m: name 'langsmith_rag' is not defined"
     ]
    }
   ],
   "source": [
    "question = \"What is LangSmith used for?\"\n",
    "ai_answer = langsmith_rag(question, langsmith_extra={\"metadata\": {\"website\": \"www.google.com\"}})\n",
    "print(ai_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's take a look in LangSmith!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
